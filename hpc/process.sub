#!/bin/bash
#SBATCH --qos medium
#SBATCH --account iacc_gbuzzell
#SBATCH --partition 6g-per-core


#SBATCH --nodes=1                # node count
#SBATCH --ntasks=1               # total number of tasks across all nodes
#SBATCH --cpus-per-task=1        # CPUS to use when using data parallelization
#SBATCH --time=05:00:00          # total run time limit (HH:MM:SS)

# load singularity module
module load singularity-3.5.3

# edit variables here to change inputs and outputs
project="readAloud-valence-dataset"
input_file="/home/data/NDClab/datasets/$project/sourcedata/raw/redcap/AnInvestigationIntoC_DATA_2022-02-16_1101.csv"
output_file="~/Downloads/outputs.csv"

# paths to static code and data
sing_image="containers/singularity/inst-container.simg"
json_scorer="scripts/json_scorer.py"
survey_data="scripts/surveys.json"

# use singularity image to run script
singularity exec --bind /home/data/NDClab/datasets/$project/sourcedata,/home/data/NDClab/tools/instruments \
    $sing_image \
    python3 $json_scorer \
    $input_file \
    $survey_data \
    $output_file


